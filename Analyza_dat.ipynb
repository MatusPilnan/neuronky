{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analýza dát\n",
    "===========\n",
    "Zámerom nášho projektu je natrénovať konvolučnú neurónovú sieť, aby dokázala filtrovať zašumený obraz. Náš dataset predstavuje množina dvojíc zašumený obraz-bezchybný obraz.\n",
    "\n",
    "## Pôvod datasetu\n",
    "Použitý dataset pozostáva zo skupiny 200 dvojíc obrázkov zachytávajúcich rôzne scény, vyhotovených na pätici rôznych smartfónov. Celý dataset je dostupný na tejto [stránke](https://www.eecs.yorku.ca/~kamel/sidd/dataset.php).\n",
    "\n",
    "## Ukážky\n",
    "TODO\n",
    "aa\n",
    "## Voláke grafíky?\n",
    "\n",
    "## Validácia\n",
    "??\n",
    "\n",
    "## Spôsov vyhodnocovania\n",
    "V rámci objektívneho vyhodnocovania výsledkov našej neurónovej siete pri rôznych nastaveniach hyperparametrov využijeme absolútny rozdiel pixelových hodnôt bezchybného obrazu na vstupe a výsledného obrazu po predikcii našou neurónovou sieťou. Vizualizácia tohto rozdielu nám pomôže odhaliť, ktoré prvky či javy obrazu robia sieti problémy a s ktorými sa naopak dokáže vysporiadať."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import math\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from models import DnCNN, dcnn_loss\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "PATCH_SIZE = 140\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "TEST_SIZE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_image_data(scenes=None):\n",
    "    def decode_img(img):\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32, True)\n",
    "        img = tf.expand_dims(img, 0)\n",
    "        img = tf.image.extract_patches(img,\n",
    "                                       [1, PATCH_SIZE, PATCH_SIZE, 1],\n",
    "                                       [1, PATCH_SIZE, PATCH_SIZE, 1],\n",
    "                                       [1, 1, 1, 1],\n",
    "                                       padding='VALID')\n",
    "        img = tf.reshape(img, [-1, PATCH_SIZE, PATCH_SIZE, 3])\n",
    "        return img\n",
    "\n",
    "    def process_path(file_path):\n",
    "        noisy = tf.io.read_file(path + file_path + '/NOISY_SRGB_010.PNG')\n",
    "        gt = tf.io.read_file(path + file_path + '/GT_SRGB_010.PNG')\n",
    "        noisy = decode_img(noisy)\n",
    "        gt = decode_img(gt)\n",
    "        return noisy, gt\n",
    "\n",
    "    path = 'datasets/SIDD_Small_sRGB_Only/SIDD_Small_sRGB_Only/Data/'\n",
    "    f = open('datasets/SIDD_Small_sRGB_Only/SIDD_Small_sRGB_Only/Scene_Instances.txt')\n",
    "    scene_instances = f.readlines()\n",
    "    paths = None\n",
    "    if scenes is not None:\n",
    "        regex = ''\n",
    "        for scene in scenes:\n",
    "            regex = regex + '_%03d_|' % scene\n",
    "        regex = regex[:-1]\n",
    "        scene_instances = [i for i in scene_instances if re.search(regex, i)]\n",
    "        paths = tf.data.Dataset.from_tensors(scene_instances)\n",
    "\n",
    "    paths = tf.data.TextLineDataset('datasets/SIDD_Small_sRGB_Only/SIDD_Small_sRGB_Only/Scene_Instances.txt')\n",
    "\n",
    "    x = paths.map(process_path)\n",
    "    return x\n",
    "\n",
    "\n",
    "def image_to_patches(image):\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    image_patches = tf.image.extract_patches(image,\n",
    "                                       [1, PATCH_SIZE, PATCH_SIZE, 1],\n",
    "                                       [1, PATCH_SIZE, PATCH_SIZE, 1],\n",
    "                                       [1, 1, 1, 1],\n",
    "                                       padding='SAME')\n",
    "    image_patches = tf.reshape(image_patches, [-1, PATCH_SIZE, PATCH_SIZE, 3])\n",
    "    return image_patches\n",
    "\n",
    "\n",
    "def use_predict_on_patches(image_patches, model):\n",
    "    predicted_patches = []\n",
    "\n",
    "    for i in range(len(image_patches)):\n",
    "        predicted_patches.append(model.predict(np.expand_dims(image_patches[i], 0)))\n",
    "        print('Prediction done ' + str(image_patches[i].shape))\n",
    "    return predicted_patches\n",
    "\n",
    "\n",
    "def patches_to_image(patches, height, width):\n",
    "    num_of_patches_vertical = math.ceil(height / PATCH_SIZE)\n",
    "    num_of_patches_horizontal = math.ceil(width / PATCH_SIZE)\n",
    "\n",
    "    print('Height is: ' + str(height))\n",
    "    print('Width is: ' + str(width))\n",
    "\n",
    "    print('Vertical number of patches is: ' + str(num_of_patches_vertical))\n",
    "    print('Horizontal number of patches is: ' + str(num_of_patches_horizontal))\n",
    "\n",
    "    pad = [[0, 0], [0, 0]]\n",
    "\n",
    "    reconstructed_patches = tf.reshape(patches, [1, num_of_patches_vertical, num_of_patches_horizontal, PATCH_SIZE * PATCH_SIZE, 3])\n",
    "    reconstructed_patches = tf.split(reconstructed_patches, PATCH_SIZE * PATCH_SIZE, 3)\n",
    "    reconstructed_patches = tf.stack(reconstructed_patches, axis=0)\n",
    "    reconstructed_patches = tf.reshape(reconstructed_patches, [PATCH_SIZE * PATCH_SIZE, num_of_patches_vertical, num_of_patches_horizontal, 3])\n",
    "\n",
    "    result = tf.batch_to_space(reconstructed_patches, [PATCH_SIZE, PATCH_SIZE], pad)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = load_image_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = x.unbatch()\n",
    "x = x.batch(batch_size=10)\n",
    "shuffled_data = x.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n",
    "test = shuffled_data.take(TEST_SIZE).repeat()\n",
    "train = shuffled_data.skip(TEST_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Train for 3 steps, validate for 10 steps\nEpoch 1/10\n",
      "\r1/3 [=========>....................] - ETA: 14s - loss: 136277.6250 - accuracy: 0.4376",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/3 [===================>..........] - ETA: 4s - loss: 112098.3086 - accuracy: 0.4261 ",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 11s 4s/step - loss: 82555.3242 - accuracy: 0.4014 - val_loss: 207.3288 - val_accuracy: 0.8483\n",
      "Epoch 2/10\n",
      "\r1/3 [=========>....................] - ETA: 0s - loss: 10674.9043 - accuracy: 0.3920",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/3 [===================>..........] - ETA: 0s - loss: 12148.3730 - accuracy: 0.5749",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 4s 1s/step - loss: 9061.1193 - accuracy: 0.5263 - val_loss: 239.0855 - val_accuracy: 0.9061\n",
      "Epoch 3/10\n",
      "\r1/3 [=========>....................] - ETA: 0s - loss: 2199.8303 - accuracy: 0.1303",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/3 [===================>..........] - ETA: 0s - loss: 1937.3776 - accuracy: 0.2524"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model = DnCNN(depth=20)\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=dcnn_loss, metrics=['accuracy'])\n",
    "\n",
    "now = datetime.now()\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "    log_dir='logs\\log_from_{}'.format(now.strftime(\"%Y-%m-%d_at_%H-%M-%S\")),\n",
    "    histogram_freq=1)\n",
    "\n",
    "model.fit(x=train, steps_per_epoch=3, validation_data=test, epochs=10, validation_steps=10, callbacks=[tensorboard_callback])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "model.save('models\\model_made_on_{}'.format(now.strftime(\"%Y-%m-%d_at_%H-%M-%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loaded = keras.models.load_model('models/model_made_on_2019-11-16_at_02-03-01', compile=False)\n",
    "loaded.compile(optimizer=keras.optimizers.Adam(), loss=dcnn_loss, metrics=['accuracy'])\n",
    "image = mpimg.imread('datasets/SIDD_Small_sRGB_Only/SIDD_Small_sRGB_Only/Data/0118_006_N6_00100_00025_3200_L/NOISY_SRGB_010.PNG')\n",
    "\n",
    "image_patches = image_to_patches(image)\n",
    "\n",
    "reconstructed_patches = use_predict_on_patches(image_patches, loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "joined_image = patches_to_image(image_patches, image.shape[0], image.shape[1])\n",
    "reconstructed_image = patches_to_image(reconstructed_patches, image.shape[0], image.shape[1])\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(joined_image[0])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(reconstructed_image[0])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}